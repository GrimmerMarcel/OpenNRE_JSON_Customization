{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter relevante Wörter für Embeddingmatrix\n",
    "\n",
    "Falls nur auf einer Teilmenge der Trainingsdaten gearbeitet wird, werden ebenfalls nur die Wörter benötigt, die in dieser Teilmenge vorhanden sind. Das reduziert die Dimension der Embeddingmatrix, was zu einer verbesserten Performance führt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Trainingsdaten\n",
    "import json\n",
    "with open('train.json') as json_file: \n",
    "    traindata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Testdaten\n",
    "with open('test.json') as json_file: \n",
    "    testdata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_vec.json') as json_file: \n",
    "    wordvec = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ableiten der relevanten Wörter + Cleaning (Duplikate, Zeichen etc.)\n",
    "i = 0\n",
    "allwords = []\n",
    "merged_data = traindata + testdata\n",
    "for item in merged_data:\n",
    "    # preprocess and save words in list\n",
    "    s = item['sentence'].replace(\"'\",\"\")\n",
    "    s = s.replace(\",\",\"\")\n",
    "    s = s.replace(\".\",\"\")\n",
    "    words = s.split(\" \")\n",
    "    words = list(filter(None, words))\n",
    "    words = list(set(words))\n",
    "    words = [ x.lower() for x in words ]\n",
    "    allwords = words + list(set(allwords) - set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellt Liste mit relevanten Wörtern\n",
    "relwords = []\n",
    "for worditem in wordvec:\n",
    "    if worditem['word'] in allwords:\n",
    "        relwords.append(worditem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichert Liste als JSON-File ab\n",
    "# VORSICHT: Format in UTF-8 umwandeln vor VErwendung mit OpenNRE\n",
    "with open('rel_word_vec.json', 'w') as f:\n",
    "    for item in relwords:\n",
    "        json.dump(item,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
